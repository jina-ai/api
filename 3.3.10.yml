name: Jina
description: Cloud-native neural search framework for any kind of data
license: Apache 2.0
vendor: Jina AI Limited
source: https://github.com/jina-ai/jina/tree/master
url: https://jina.ai
docs: https://docs.jina.ai
authors: dev-team@jina.ai
version: 3.3.10
methods:
- name: hello
  options: []
  help: Start hello world demos.
  methods:
  - name: fashion
    options:
    - help: The workdir for hello-world demoall data, indices, shards and outputs
        will be saved there
      choices: null
      default: 362d8291029549d9ae59fc1134dbdfd8
      required: false
      option_strings:
      - --workdir
      type: str
      default_random: false
      name: workdir
    - help: The proxy when downloading sample data
      choices: null
      default: null
      required: false
      option_strings:
      - --download-proxy
      type: str
      default_random: false
      name: download_proxy
    - help: The url of index data (should be in idx3-ubyte.gz format)
      choices: null
      default: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz
      required: false
      option_strings:
      - --index-data-url
      type: str
      default_random: false
      name: index_data_url
    - help: The url of index labels data (should be in idx3-ubyte.gz format)
      choices: null
      default: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz
      required: false
      option_strings:
      - --index-labels-url
      type: str
      default_random: false
      name: index_labels_url
    - help: The url of query data (should be in idx3-ubyte.gz format)
      choices: null
      default: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz
      required: false
      option_strings:
      - --query-data-url
      type: str
      default_random: false
      name: query_data_url
    - help: The url of query labels data (should be in idx3-ubyte.gz format)
      choices: null
      default: http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz
      required: false
      option_strings:
      - --query-labels-url
      type: str
      default_random: false
      name: query_labels_url
    - help: The number of queries to visualize
      choices: null
      default: 128
      required: false
      option_strings:
      - --num-query
      type: int
      default_random: false
      name: num_query
    - help: Top-k results to retrieve and visualize
      choices: null
      default: 50
      required: false
      option_strings:
      - --top-k
      type: int
      default_random: false
      name: top_k
    help: Run a fashion search demo
  - name: chatbot
    options:
    - help: The workdir for hello-world demoall data, indices, shards and outputs
        will be saved there
      choices: null
      default: 49e3ce3c69f04cb9b60777ee3804a502
      required: false
      option_strings:
      - --workdir
      type: str
      default_random: false
      name: workdir
    - help: The proxy when downloading sample data
      choices: null
      default: null
      required: false
      option_strings:
      - --download-proxy
      type: str
      default_random: false
      name: download_proxy
    - help: The url of index csv data
      choices: null
      default: https://static.jina.ai/chatbot/dataset.csv
      required: false
      option_strings:
      - --index-data-url
      type: str
      default_random: false
      name: index_data_url
    - help: The port of the host exposed to the public
      choices: null
      default: 8080
      required: false
      option_strings:
      - --port
      type: int
      default_random: false
      name: port
    - help: The number of replicas when index and query
      choices: null
      default: 2
      required: false
      option_strings:
      - --replicas
      type: int
      default_random: false
      name: replicas
    help: Run a chatbot QA demo
  - name: multimodal
    options:
    - help: The workdir for hello-world demoall data, indices, shards and outputs
        will be saved there
      choices: null
      default: ca7df4e427854e98a9baa8b77ef593ac
      required: false
      option_strings:
      - --workdir
      type: str
      default_random: false
      name: workdir
    - help: The proxy when downloading sample data
      choices: null
      default: null
      required: false
      option_strings:
      - --download-proxy
      type: str
      default_random: false
      name: download_proxy
    - help: The url of index csv data
      choices: null
      default: https://static.jina.ai/multimodal/people-img.zip
      required: false
      option_strings:
      - --index-data-url
      type: str
      default_random: false
      name: index_data_url
    - help: The port of the host exposed to the public
      choices: null
      default: 8080
      required: false
      option_strings:
      - --port
      type: int
      default_random: false
      name: port
    help: Run a multimodal search demo
  - name: fork
    options:
    - help: The hello world project to fork
      choices:
      - fashion
      - chatbot
      - multimodal
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: project
    - help: The dest directory of the forked project. Note, it can not be an existing
        path.
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: destination
    help: Fork a hello world project to a local directory.
- name: executor
  options:
  - help: "\nThe name of this object.\n\nThis will be used in the following places:\n\
      - how you refer to this object in Python/YAML/CLI\n- visualization\n- log message\
      \ header\n- ...\n\nWhen not given, then the default naming strategy will apply.\n\
      \                    "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: /opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/jina/resources/logging.default.yml
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * an Executor YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub\
      \ Executor (must start with `jinahub://` or `jinahub+docker://`)\n        *\
      \ a docker image (must start with `docker://`)\n        * the string literal\
      \ of a YAML config (must start with `!` or `jtype: `)\n        * the string\
      \ literal of a JSON config\n\n        When use it under Python, one can use\
      \ the following values additionally:\n        - a Python dict that represents\
      \ the config\n        - a text file stream has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: The port for input data to bind to, default a random port between [49152,
      65535]
    choices: null
    default: 57109
    required: false
    option_strings:
    - --port-in
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: The host address for binding to, by default it is 0.0.0.0
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host-in
    type: str
    default_random: false
    name: host_in
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: Pull the latest image before running
    choices: null
    default: false
    required: false
    option_strings:
    - --pull-latest
    type: bool
    default_random: false
    name: pull_latest
  - help: "\nThe path on the host to be mounted inside the container. \n\nNote, \n\
      - If separated by `:`, then the first part will be considered as the local host\
      \ path and the second part is the path in the container system. \n- If no split\
      \ provided, then the basename of that directory will be mounted into container's\
      \ root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into\
      \ `/my-workspace` inside the container. \n- All volumes are mounted with read-write\
      \ mode.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --volumes
    type: typing.List[str]
    default_random: false
    name: volumes
  - help: "\n    This argument allows dockerized Jina executor discover local gpu\
      \ devices.\n\n    Note, \n    - To access all gpus, use `--gpus all`.\n    -\
      \ To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.\n    - To\
      \ access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`\n\
      \    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`\n\
      \    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n\
      \    "
    choices: null
    default: null
    required: false
    option_strings:
    - --gpus
    type: str
    default_random: false
    name: gpus
  - help: Do not automatically mount a volume for dockerized Executors.
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-auto-volume
    type: bool
    default_random: false
    name: disable_auto_volume
  - help: The host address of the runtime, by default it is 0.0.0.0.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    type: str
    default_random: false
    name: host
  - help: Do not display the streaming of remote logs on local console
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-remote-logs
    type: bool
    default_random: false
    name: quiet_remote_logs
  - help: '

      The files on the host to be uploaded to the remote

      workspace. This can be useful when your Deployment has more

      file dependencies beyond a single YAML file, e.g.

      Python files, data files.


      Note,

      - currently only flatten structure is supported, which means if you upload `[./foo/a.py,
      ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace
      on the remote, losing all hierarchies.

      - by default, `--uses` YAML file is always uploaded.

      - uploaded files are by default isolated across the runs. To ensure files are
      submitted to the same workspace across different runs, use `--workspace-id`
      to specify the workspace.

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --upload-files
    type: typing.List[str]
    default_random: false
    name: upload_files
  - help: The runtime class to run inside the Pod
    choices: null
    default: WorkerRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: The port for input data to bind to, default is a random port between [49152,
      65535]
    choices: null
    default: 57495
    required: false
    option_strings:
    - --port
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: 'The port on which the prometheus server is exposed, default port is 9090 '
    choices: null
    default: 9090
    required: false
    option_strings:
    - --port-monitoring
    type: int
    default_random: false
    name: port_monitoring
  - help: If set, install `requirements.txt` in the Hub Executor bundle to local
    choices: null
    default: false
    required: false
    option_strings:
    - --install-requirements
    type: bool
    default_random: false
    name: install_requirements
  - help: If set, always pull the latest Hub Executor bundle even it exists on local
    choices: null
    default: false
    required: false
    option_strings:
    - --force-update
    - --force
    type: bool
    default_random: false
    name: force_update
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. Possibilities are `NoCompression, Gzip, Deflate`. For more details,
      check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices: null
    default: NoCompression
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before-address
    type: str
    default_random: false
    name: uses_before_address
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after-address
    type: str
    default_random: false
    name: uses_after_address
  - help: dictionary JSON with a list of connections to configure
    choices: null
    default: null
    required: false
    option_strings:
    - --connection-list
    type: str
    default_random: false
    name: connection_list
  - help: Disable the built-in reduce mechanism, set this if the reduction is to be
      handled by the Executor connected to this Head
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-reduce
    type: bool
    default_random: false
    name: disable_reduce
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  help: Start an Executor. Executor is how Jina processes Document.
- name: flow
  options:
  - help: "\nThe name of this object.\n\nThis will be used in the following places:\n\
      - how you refer to this object in Python/YAML/CLI\n- visualization\n- log message\
      \ header\n- ...\n\nWhen not given, then the default naming strategy will apply.\n\
      \                    "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: /opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/jina/resources/logging.default.yml
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: 'If set, /graphql endpoint is added to HTTP interface. '
    choices: null
    default: false
    required: false
    option_strings:
    - --expose-graphql-endpoint
    type: bool
    default_random: false
    name: expose_graphql_endpoint
  - help: The YAML file represents a flow
    choices: null
    default: null
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: "\n    The strategy on those inspect deployments in the flow.\n\n    If\
      \ `REMOVE` is given then all inspect deployments are removed when building the\
      \ flow.\n    "
    choices:
    - HANG
    - REMOVE
    - COLLECT
    default: COLLECT
    required: false
    option_strings:
    - --inspect
    type: str
    default_random: false
    name: inspect
  help: Start a Flow. Flow is how Jina streamlines and distributes Executors.
- name: ping
  options:
  - help: The host address of the target Pod, e.g. 0.0.0.0
    choices: null
    default: null
    required: true
    option_strings: []
    type: str
    default_random: false
    name: host
  - help: The control port of the target deployment/pod
    choices: null
    default: null
    required: true
    option_strings: []
    type: int
    default_random: false
    name: port
  - help: '

      Timeout in millisecond of one check

      -1 for waiting forever

      '
    choices: null
    default: 3000
    required: false
    option_strings:
    - --timeout
    type: int
    default_random: false
    name: timeout
  - help: The max number of tried health checks before exit with exit code 1
    choices: null
    default: 3
    required: false
    option_strings:
    - --retries
    type: int
    default_random: false
    name: retries
  help: Ping a Deployment and check its network connectivity.
- name: new
  options:
  - help: The name of the project
    choices: null
    default: hello-jina
    required: true
    option_strings: []
    type: str
    default_random: false
    name: name
  help: Create a new Jina toy project with the predefined template.
- name: gateway
  options:
  - help: "\nThe name of this object.\n\nThis will be used in the following places:\n\
      - how you refer to this object in Python/YAML/CLI\n- visualization\n- log message\
      \ header\n- ...\n\nWhen not given, then the default naming strategy will apply.\n\
      \                    "
    choices: null
    default: gateway
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: /opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/jina/resources/logging.default.yml
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * an Executor YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub\
      \ Executor (must start with `jinahub://` or `jinahub+docker://`)\n        *\
      \ a docker image (must start with `docker://`)\n        * the string literal\
      \ of a YAML config (must start with `!` or `jtype: `)\n        * the string\
      \ literal of a JSON config\n\n        When use it under Python, one can use\
      \ the following values additionally:\n        - a Python dict that represents\
      \ the config\n        - a text file stream has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: The port for input data to bind to, default a random port between [49152,
      65535]
    choices: null
    default: 54786
    required: false
    option_strings:
    - --port-in
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: The host address for binding to, by default it is 0.0.0.0
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host-in
    type: str
    default_random: false
    name: host_in
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: "\n    Number of requests fetched from the client before feeding into the\
      \ first Executor. \n    \n    Used to control the speed of data input into a\
      \ Flow. 0 disables prefetch (disabled by default)"
    choices: null
    default: 0
    required: false
    option_strings:
    - --prefetch
    type: int
    default_random: false
    name: prefetch
  - help: The title of this HTTP server. It will be used in automatics docs such as
      Swagger UI.
    choices: null
    default: null
    required: false
    option_strings:
    - --title
    type: str
    default_random: false
    name: title
  - help: The description of this HTTP server. It will be used in automatics docs
      such as Swagger UI.
    choices: null
    default: null
    required: false
    option_strings:
    - --description
    type: str
    default_random: false
    name: description
  - help: "\n        If set, a CORS middleware is added to FastAPI frontend to allow\
      \ cross-origin access.\n        "
    choices: null
    default: false
    required: false
    option_strings:
    - --cors
    type: bool
    default_random: false
    name: cors
  - help: 'If set, the default swagger ui is used for `/docs` endpoint. '
    choices: null
    default: false
    required: false
    option_strings:
    - --default-swagger-ui
    type: bool
    default_random: false
    name: default_swagger_ui
  - help: 'If set, /status /post endpoints are removed from HTTP interface. '
    choices: null
    default: false
    required: false
    option_strings:
    - --no-debug-endpoints
    type: bool
    default_random: false
    name: no_debug_endpoints
  - help: "\n        If set, /index, /search, /update, /delete endpoints are removed\
      \ from HTTP interface.\n\n        Any executor that has `@requests(on=...)`\
      \ bind with those values will receive data requests.\n        "
    choices: null
    default: false
    required: false
    option_strings:
    - --no-crud-endpoints
    type: bool
    default_random: false
    name: no_crud_endpoints
  - help: "\n        A JSON string that represents a map from executor endpoints (`@requests(on=...)`)\
      \ to HTTP endpoints.\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --expose-endpoints
    type: str
    default_random: false
    name: expose_endpoints
  - help: '

      Dictionary of kwargs arguments that will be passed to Uvicorn server when starting
      the server


      More details can be found in Uvicorn docs: https://www.uvicorn.org/settings/


      '
    choices: null
    default: null
    required: false
    option_strings:
    - --uvicorn-kwargs
    type: dict
    default_random: false
    name: uvicorn_kwargs
  - help: "\n    Dictionary of kwargs arguments that will be passed to the grpc server\
      \ when starting the server # todo update\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --grpc-server-kwargs
    type: dict
    default_random: false
    name: grpc_server_kwargs
  - help: "\n        the path to the certificate file\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --ssl-certfile
    type: str
    default_random: false
    name: ssl_certfile
  - help: "\n        the path to the key file\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --ssl-keyfile
    type: str
    default_random: false
    name: ssl_keyfile
  - help: 'If set, /graphql endpoint is added to HTTP interface. '
    choices: null
    default: false
    required: false
    option_strings:
    - --expose-graphql-endpoint
    type: bool
    default_random: false
    name: expose_graphql_endpoint
  - help: Communication protocol between server and client.
    choices:
    - GRPC
    - HTTP
    - WEBSOCKET
    default: GRPC
    required: false
    option_strings:
    - --protocol
    type: str
    default_random: false
    name: protocol
  - help: The host address of the runtime, by default it is 0.0.0.0.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    type: str
    default_random: false
    name: host
  - help: If set, respect the http_proxy and https_proxy environment variables. otherwise,
      it will unset these proxy variables before start. gRPC seems to prefer no proxy
    choices: null
    default: false
    required: false
    option_strings:
    - --proxy
    type: bool
    default_random: false
    name: proxy
  - help: The port that the gateway exposes for clients for GRPC connections.
    choices: null
    default: 59522
    required: false
    option_strings:
    - --port-expose
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: Routing graph for the gateway
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --graph-description
    type: str
    default_random: false
    name: graph_description
  - help: Dictionary stating which filtering conditions each Executor in the graph
      requires to receive Documents.
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --graph-conditions
    type: str
    default_random: false
    name: graph_conditions
  - help: dictionary JSON with the input addresses of each Deployment
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --deployments-addresses
    type: str
    default_random: false
    name: deployments_addresses
  - help: list JSON disabling the built-in merging mechanism for each Deployment listed
    choices: null
    default: '[]'
    required: false
    option_strings:
    - --deployments-disable-reduce
    type: str
    default_random: false
    name: deployments_disable_reduce
  - help: 'The compression mechanism used when sending requests to Executors. Possibilites
      are: `NoCompression, Gzip, Deflate`. For more details, check https://grpc.github.io/grpc/python/grpc.html#compression.'
    choices: null
    default: NoCompression
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  - help: The runtime class to run inside the Pod
    choices: null
    default: GRPCGatewayRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: The port for input data to bind to, default is a random port between [49152,
      65535]
    choices: null
    default: 62199
    required: false
    option_strings:
    - --port
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: 'The port on which the prometheus server is exposed, default port is 9090 '
    choices: null
    default: 9090
    required: false
    option_strings:
    - --port-monitoring
    type: int
    default_random: false
    name: port_monitoring
  help: Start a Gateway that receives client Requests via gRPC/REST interface
- name: hub
  options: []
  help: Push/Pull an Executor to/from Jina Hub
  methods:
  - name: new
    options:
    - help: the name of the Executor
      choices: null
      default: null
      required: false
      option_strings:
      - --name
      type: str
      default_random: false
      name: name
    - help: the path to store the Executor
      choices: null
      default: null
      required: false
      option_strings:
      - --path
      type: str
      default_random: false
      name: path
    - help: If set, always set up advance configuration like description, keywords
        and url
      choices: null
      default: false
      required: false
      option_strings:
      - --advance-configuration
      type: bool
      default_random: false
      name: advance_configuration
    - help: the short description of the Executor
      choices: null
      default: null
      required: false
      option_strings:
      - --description
      type: str
      default_random: false
      name: description
    - help: some keywords to help people search your Executor (separated by comma)
      choices: null
      default: null
      required: false
      option_strings:
      - --keywords
      type: str
      default_random: false
      name: keywords
    - help: the URL of your GitHub repo
      choices: null
      default: null
      required: false
      option_strings:
      - --url
      type: str
      default_random: false
      name: url
    - help: If set, add a Dockerfile to the created Executor bundle
      choices: null
      default: false
      required: false
      option_strings:
      - --add-dockerfile
      type: bool
      default_random: false
      name: add_dockerfile
    help: Create a new executor using the template
  - name: push
    options:
    - help: If set, Hub executor usage will not be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --no-usage
      type: bool
      default_random: false
      name: no_usage
    - help: If set, more information will be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --verbose
      type: bool
      default_random: false
      name: verbose
    - help: The Executor folder to be pushed to Jina Hub
      choices: null
      default: null
      required: true
      option_strings: []
      type: dir_path
      default_random: false
      name: path
    - help: The file path to the Dockerfile (default is `${cwd}/Dockerfile`)
      choices: null
      default: null
      required: false
      option_strings:
      - -f
      - --dockerfile
      type: None
      default_random: false
      name: dockerfile
    - help: If set, push will overwrite the Executor on the Hub that shares the same
        NAME or UUID8 identifier
      choices: null
      default: null
      required: false
      option_strings:
      - --force-update
      - --force
      type: str
      default_random: false
      name: force_update
    - help: The secret for overwrite a Hub executor
      choices: null
      default: null
      required: false
      option_strings:
      - --secret
      type: str
      default_random: false
      name: secret
    - help: If set, "--no-cache" option will be added to the Docker build.
      choices: null
      default: false
      required: false
      option_strings:
      - --no-cache
      type: bool
      default_random: false
      name: no_cache
    - help: If set, the pushed executor is visible to public
      choices: null
      default: ==SUPPRESS==
      required: false
      option_strings:
      - --public
      type: bool
      default_random: false
      name: public
    - help: If set, the pushed executor is invisible to public
      choices: null
      default: ==SUPPRESS==
      required: false
      option_strings:
      - --private
      type: bool
      default_random: false
      name: private
    help: Push an executor package to Jina hub
  - name: pull
    options:
    - help: If set, Hub executor usage will not be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --no-usage
      type: bool
      default_random: false
      name: no_usage
    - help: The URI of the executor to pull (e.g., jinahub[+docker]://NAME)
      choices: null
      default: null
      required: true
      option_strings: []
      type: hub_uri
      default_random: false
      name: uri
    - help: If set, install `requirements.txt` in the Hub Executor bundle to local
      choices: null
      default: false
      required: false
      option_strings:
      - --install-requirements
      type: bool
      default_random: false
      name: install_requirements
    - help: If set, always pull the latest Hub Executor bundle even it exists on local
      choices: null
      default: false
      required: false
      option_strings:
      - --force-update
      - --force
      type: bool
      default_random: false
      name: force_update
    help: Download an executor image/package from Jina hub
- name: help
  options:
  - help: Lookup the usage & mention of the argument name in Jina API. The name can
      be fuzzy
    choices: null
    default: null
    required: true
    option_strings: []
    type: str
    default_random: false
    name: query
  help: Show help text of a CLI argument
- name: pod
  options:
  - help: "\nThe name of this object.\n\nThis will be used in the following places:\n\
      - how you refer to this object in Python/YAML/CLI\n- visualization\n- log message\
      \ header\n- ...\n\nWhen not given, then the default naming strategy will apply.\n\
      \                    "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: /opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/jina/resources/logging.default.yml
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * an Executor YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub\
      \ Executor (must start with `jinahub://` or `jinahub+docker://`)\n        *\
      \ a docker image (must start with `docker://`)\n        * the string literal\
      \ of a YAML config (must start with `!` or `jtype: `)\n        * the string\
      \ literal of a JSON config\n\n        When use it under Python, one can use\
      \ the following values additionally:\n        - a Python dict that represents\
      \ the config\n        - a text file stream has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: The port for input data to bind to, default a random port between [49152,
      65535]
    choices: null
    default: 50277
    required: false
    option_strings:
    - --port-in
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: The host address for binding to, by default it is 0.0.0.0
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host-in
    type: str
    default_random: false
    name: host_in
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: Pull the latest image before running
    choices: null
    default: false
    required: false
    option_strings:
    - --pull-latest
    type: bool
    default_random: false
    name: pull_latest
  - help: "\nThe path on the host to be mounted inside the container. \n\nNote, \n\
      - If separated by `:`, then the first part will be considered as the local host\
      \ path and the second part is the path in the container system. \n- If no split\
      \ provided, then the basename of that directory will be mounted into container's\
      \ root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into\
      \ `/my-workspace` inside the container. \n- All volumes are mounted with read-write\
      \ mode.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --volumes
    type: typing.List[str]
    default_random: false
    name: volumes
  - help: "\n    This argument allows dockerized Jina executor discover local gpu\
      \ devices.\n\n    Note, \n    - To access all gpus, use `--gpus all`.\n    -\
      \ To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.\n    - To\
      \ access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`\n\
      \    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`\n\
      \    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n\
      \    "
    choices: null
    default: null
    required: false
    option_strings:
    - --gpus
    type: str
    default_random: false
    name: gpus
  - help: Do not automatically mount a volume for dockerized Executors.
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-auto-volume
    type: bool
    default_random: false
    name: disable_auto_volume
  - help: The host address of the runtime, by default it is 0.0.0.0.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    type: str
    default_random: false
    name: host
  - help: Do not display the streaming of remote logs on local console
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-remote-logs
    type: bool
    default_random: false
    name: quiet_remote_logs
  - help: '

      The files on the host to be uploaded to the remote

      workspace. This can be useful when your Deployment has more

      file dependencies beyond a single YAML file, e.g.

      Python files, data files.


      Note,

      - currently only flatten structure is supported, which means if you upload `[./foo/a.py,
      ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace
      on the remote, losing all hierarchies.

      - by default, `--uses` YAML file is always uploaded.

      - uploaded files are by default isolated across the runs. To ensure files are
      submitted to the same workspace across different runs, use `--workspace-id`
      to specify the workspace.

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --upload-files
    type: typing.List[str]
    default_random: false
    name: upload_files
  - help: The runtime class to run inside the Pod
    choices: null
    default: WorkerRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: The port for input data to bind to, default is a random port between [49152,
      65535]
    choices: null
    default: 61769
    required: false
    option_strings:
    - --port
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: 'The port on which the prometheus server is exposed, default port is 9090 '
    choices: null
    default: 9090
    required: false
    option_strings:
    - --port-monitoring
    type: int
    default_random: false
    name: port_monitoring
  - help: If set, install `requirements.txt` in the Hub Executor bundle to local
    choices: null
    default: false
    required: false
    option_strings:
    - --install-requirements
    type: bool
    default_random: false
    name: install_requirements
  - help: If set, always pull the latest Hub Executor bundle even it exists on local
    choices: null
    default: false
    required: false
    option_strings:
    - --force-update
    - --force
    type: bool
    default_random: false
    name: force_update
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. Possibilities are `NoCompression, Gzip, Deflate`. For more details,
      check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices: null
    default: NoCompression
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before-address
    type: str
    default_random: false
    name: uses_before_address
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after-address
    type: str
    default_random: false
    name: uses_after_address
  - help: dictionary JSON with a list of connections to configure
    choices: null
    default: null
    required: false
    option_strings:
    - --connection-list
    type: str
    default_random: false
    name: connection_list
  - help: Disable the built-in reduce mechanism, set this if the reduction is to be
      handled by the Executor connected to this Head
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-reduce
    type: bool
    default_random: false
    name: disable_reduce
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  help: Start a Pod. You should rarely use this directly unless you are doing low-level
    orchestration
- name: deployment
  options:
  - help: "\nThe name of this object.\n\nThis will be used in the following places:\n\
      - how you refer to this object in Python/YAML/CLI\n- visualization\n- log message\
      \ header\n- ...\n\nWhen not given, then the default naming strategy will apply.\n\
      \                    "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: /opt/hostedtoolcache/Python/3.7.12/x64/lib/python3.7/site-packages/jina/resources/logging.default.yml
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * an Executor YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub\
      \ Executor (must start with `jinahub://` or `jinahub+docker://`)\n        *\
      \ a docker image (must start with `docker://`)\n        * the string literal\
      \ of a YAML config (must start with `!` or `jtype: `)\n        * the string\
      \ literal of a JSON config\n\n        When use it under Python, one can use\
      \ the following values additionally:\n        - a Python dict that represents\
      \ the config\n        - a text file stream has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/repository-structure/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: The port for input data to bind to, default a random port between [49152,
      65535]
    choices: null
    default: 54696
    required: false
    option_strings:
    - --port-in
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: The host address for binding to, by default it is 0.0.0.0
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host-in
    type: str
    default_random: false
    name: host_in
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: Pull the latest image before running
    choices: null
    default: false
    required: false
    option_strings:
    - --pull-latest
    type: bool
    default_random: false
    name: pull_latest
  - help: "\nThe path on the host to be mounted inside the container. \n\nNote, \n\
      - If separated by `:`, then the first part will be considered as the local host\
      \ path and the second part is the path in the container system. \n- If no split\
      \ provided, then the basename of that directory will be mounted into container's\
      \ root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into\
      \ `/my-workspace` inside the container. \n- All volumes are mounted with read-write\
      \ mode.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --volumes
    type: typing.List[str]
    default_random: false
    name: volumes
  - help: "\n    This argument allows dockerized Jina executor discover local gpu\
      \ devices.\n\n    Note, \n    - To access all gpus, use `--gpus all`.\n    -\
      \ To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.\n    - To\
      \ access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`\n\
      \    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`\n\
      \    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n\
      \    "
    choices: null
    default: null
    required: false
    option_strings:
    - --gpus
    type: str
    default_random: false
    name: gpus
  - help: Do not automatically mount a volume for dockerized Executors.
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-auto-volume
    type: bool
    default_random: false
    name: disable_auto_volume
  - help: The host address of the runtime, by default it is 0.0.0.0.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    type: str
    default_random: false
    name: host
  - help: Do not display the streaming of remote logs on local console
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-remote-logs
    type: bool
    default_random: false
    name: quiet_remote_logs
  - help: '

      The files on the host to be uploaded to the remote

      workspace. This can be useful when your Deployment has more

      file dependencies beyond a single YAML file, e.g.

      Python files, data files.


      Note,

      - currently only flatten structure is supported, which means if you upload `[./foo/a.py,
      ./foo/b.pp, ./bar/c.yml]`, then they will be put under the _same_ workspace
      on the remote, losing all hierarchies.

      - by default, `--uses` YAML file is always uploaded.

      - uploaded files are by default isolated across the runs. To ensure files are
      submitted to the same workspace across different runs, use `--workspace-id`
      to specify the workspace.

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --upload-files
    type: typing.List[str]
    default_random: false
    name: upload_files
  - help: The runtime class to run inside the Pod
    choices: null
    default: WorkerRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: The port for input data to bind to, default is a random port between [49152,
      65535]
    choices: null
    default: 58720
    required: false
    option_strings:
    - --port
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: 'The port on which the prometheus server is exposed, default port is 9090 '
    choices: null
    default: 9090
    required: false
    option_strings:
    - --port-monitoring
    type: int
    default_random: false
    name: port_monitoring
  - help: If set, install `requirements.txt` in the Hub Executor bundle to local
    choices: null
    default: false
    required: false
    option_strings:
    - --install-requirements
    type: bool
    default_random: false
    name: install_requirements
  - help: If set, always pull the latest Hub Executor bundle even it exists on local
    choices: null
    default: false
    required: false
    option_strings:
    - --force-update
    - --force
    type: bool
    default_random: false
    name: force_update
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. Possibilities are `NoCompression, Gzip, Deflate`. For more details,
      check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices: null
    default: NoCompression
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before-address
    type: str
    default_random: false
    name: uses_before_address
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after-address
    type: str
    default_random: false
    name: uses_after_address
  - help: dictionary JSON with a list of connections to configure
    choices: null
    default: null
    required: false
    option_strings:
    - --connection-list
    type: str
    default_random: false
    name: connection_list
  - help: Disable the built-in reduce mechanism, set this if the reduction is to be
      handled by the Executor connected to this Head
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-reduce
    type: bool
    default_random: false
    name: disable_reduce
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  - help: The executor attached before the Pods described by --uses, typically before
      sending to all shards, accepted type follows `--uses`. This argument only applies
      for sharded Deployments (shards > 1).
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before
    type: str
    default_random: false
    name: uses_before
  - help: The executor attached after the Pods described by --uses, typically used
      for receiving from all shards, accepted type follows `--uses`. This argument
      only applies for sharded Deployments (shards > 1).
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after
    type: str
    default_random: false
    name: uses_after
  - help: The condition that the documents need to fulfill before reaching the Executor.The
      condition can be defined in the form of a `DocArray query condition <https://docarray.jina.ai/fundamentals/documentarray/find/#query-by-conditions>`
    choices: null
    default: null
    required: false
    option_strings:
    - --when
    type: dict
    default_random: false
    name: when
  - help: The Deployment will be considered an external Deployment that has been started
      independently from the Flow.This Deployment will not be context managed by the
      Flow.
    choices: null
    default: false
    required: false
    option_strings:
    - --external
    type: bool
    default_random: false
    name: external
  help: Start a Deployment. You should rarely use this directly unless you are doing
    low-level orchestration
- name: client
  options:
  - help: The host address of the runtime, by default it is 0.0.0.0.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    type: str
    default_random: false
    name: host
  - help: If set, respect the http_proxy and https_proxy environment variables. otherwise,
      it will unset these proxy variables before start. gRPC seems to prefer no proxy
    choices: null
    default: false
    required: false
    option_strings:
    - --proxy
    type: bool
    default_random: false
    name: proxy
  - help: The port of the Gateway, which the client should connect to.
    choices: null
    default: 49624
    required: false
    option_strings:
    - --port
    type: int
    default_random: true
    default_factory: random_port
    name: port
  - help: If set, connect to gateway using tls encryption
    choices: null
    default: false
    required: false
    option_strings:
    - --tls
    type: bool
    default_random: false
    name: tls
  - help: 'If set, then the input and output of this Client work in an asynchronous
      manner. '
    choices: null
    default: false
    required: false
    option_strings:
    - --asyncio
    type: bool
    default_random: false
    name: asyncio
  - help: If set, return results as List of Requests instead of a reduced DocArray.
    choices: null
    default: false
    required: false
    option_strings:
    - --return-responses
    type: bool
    default_random: false
    name: return_responses
  - help: Communication protocol between server and client.
    choices:
    - GRPC
    - HTTP
    - WEBSOCKET
    default: GRPC
    required: false
    option_strings:
    - --protocol
    type: str
    default_random: false
    name: protocol
  help: Start a Python client that connects to a remote Jina gateway
- name: export-api
  options:
  - help: The YAML file path for storing the exported API
    choices: null
    default: null
    required: false
    option_strings:
    - --yaml-path
    type: typing.List[str]
    default_random: false
    name: yaml_path
  - help: The JSON file path for storing the exported API
    choices: null
    default: null
    required: false
    option_strings:
    - --json-path
    type: typing.List[str]
    default_random: false
    name: json_path
  - help: The JSONSchema file path for storing the exported API
    choices: null
    default: null
    required: false
    option_strings:
    - --schema-path
    type: typing.List[str]
    default_random: false
    name: schema_path
  help: Export Jina API to JSON/YAML file for 3rd party applications
revision: null
