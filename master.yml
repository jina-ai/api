name: Jina
description: Build multimodal AI services via cloud native technologies
license: Apache 2.0
vendor: Jina AI Limited
source: https://github.com/jina-ai/jina/tree/master
url: https://jina.ai
docs: https://docs.jina.ai
authors: dev-team@jina.ai
version: 3.12.1
methods:
- name: executor
  options:
  - help: "\n    The name of this object.\n\n    This will be used in the following\
      \ places:\n    - how you refer to this object in Python/YAML/CLI\n    - visualization\n\
      \    - log message header\n    - ...\n\n    When not given, then the default\
      \ naming strategy will apply.\n                        "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: default
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * the string literal of an Executor class name\n        * an Executor\
      \ YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub Executor (must start\
      \ with `jinahub://` or `jinahub+docker://`)\n        * a docker image (must\
      \ start with `docker://`)\n        * the string literal of a YAML config (must\
      \ start with `!` or `jtype: `)\n        * the string literal of a JSON config\n\
      \n        When use it under Python, one can use the following values additionally:\n\
      \        - a Python dict that represents the config\n        - a text file stream\
      \ has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: List of exceptions that will cause the Executor to shut down.
    choices: null
    default: []
    required: false
    option_strings:
    - --exit-on-exceptions
    type: typing.List[str]
    default_random: false
    name: exit_on_exceptions
  - help: Disable the built-in reduction mechanism. Set this if the reduction is to
      be handled by the Executor itself by operating on a `docs_matrix` or `docs_map`
    choices: null
    default: false
    required: false
    option_strings:
    - --no-reduce
    - --disable-reduce
    type: bool
    default_random: false
    name: no_reduce
  - help: 'Dictionary of kwargs arguments that will be passed to the grpc server as
      options when starting the server, example : {''grpc.max_send_message_length'':
      -1}'
    choices: null
    default: null
    required: false
    option_strings:
    - --grpc-server-options
    type: dict
    default_random: false
    name: grpc_server_options
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: "\nThe path on the host to be mounted inside the container. \n\nNote, \n\
      - If separated by `:`, then the first part will be considered as the local host\
      \ path and the second part is the path in the container system. \n- If no split\
      \ provided, then the basename of that directory will be mounted into container's\
      \ root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into\
      \ `/my-workspace` inside the container. \n- All volumes are mounted with read-write\
      \ mode.\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --volumes
    type: typing.List[str]
    default_random: false
    name: volumes
  - help: "\n    This argument allows dockerized Jina Executors to discover local\
      \ gpu devices.\n    \n    Note, \n    - To access all gpus, use `--gpus all`.\n\
      \    - To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.\n \
      \   - To access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`\n\
      \    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`\n\
      \    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n\
      \        "
    choices: null
    default: null
    required: false
    option_strings:
    - --gpus
    type: str
    default_random: false
    name: gpus
  - help: Do not automatically mount a volume for dockerized Executors.
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-auto-volume
    type: bool
    default_random: false
    name: disable_auto_volume
  - help: The host address of the runtime, by default it is 0.0.0.0. In the case of
      an external Executor (`--external` or `external=True`) this can be a list of
      hosts, separated by commas. Then, every resulting address will be considered
      as one replica of the Executor.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    - --host-in
    type: str
    default_random: false
    name: host
  - help: The runtime class to run inside the Pod
    choices: null
    default: WorkerRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: If set, the current Pod/Deployment can not be further chained, and the next
      `.add()` will chain after the last Pod/Deployment not this current one.
    choices: null
    default: false
    required: false
    option_strings:
    - --floating
    type: bool
    default_random: false
    name: floating
  - help: If set, the Executor reloads the modules as they change
    choices: null
    default: false
    required: false
    option_strings:
    - --reload
    type: bool
    default_random: false
    name: reload
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: The port on which the prometheus server is exposed, default is a random
      port between [49152, 65535]
    choices: null
    default: '64585'
    required: false
    option_strings:
    - --port-monitoring
    type: str
    default_random: true
    default_factory: random_identity
    name: port_monitoring
  - help: Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)
    choices: null
    default: -1
    required: false
    option_strings:
    - --retries
    type: int
    default_random: false
    name: retries
  - help: If set, the sdk implementation of the OpenTelemetry tracer will be available
      and will be enabled for automatic tracing of requests and customer span creation.
      Otherwise a no-op implementation will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --tracing
    type: bool
    default_random: false
    name: tracing
  - help: If tracing is enabled, this hostname will be used to configure the trace
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-host
    type: str
    default_random: false
    name: traces_exporter_host
  - help: If tracing is enabled, this port will be used to configure the trace exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-port
    type: int
    default_random: false
    name: traces_exporter_port
  - help: If set, the sdk implementation of the OpenTelemetry metrics will be available
      for default monitoring and custom measurements. Otherwise a no-op implementation
      will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --metrics
    type: bool
    default_random: false
    name: metrics
  - help: If tracing is enabled, this hostname will be used to configure the metrics
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-host
    type: str
    default_random: false
    name: metrics_exporter_host
  - help: If tracing is enabled, this port will be used to configure the metrics exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-port
    type: int
    default_random: false
    name: metrics_exporter_port
  - help: If set, install `requirements.txt` in the Hub Executor bundle to local
    choices: null
    default: false
    required: false
    option_strings:
    - --install-requirements
    type: bool
    default_random: false
    name: install_requirements
  - help: If set, always pull the latest Hub Executor bundle even it exists on local
    choices: null
    default: false
    required: false
    option_strings:
    - --force-update
    - --force
    type: bool
    default_random: false
    name: force_update
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. For more details, check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices:
    - NoCompression
    - Deflate
    - Gzip
    default: null
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before-address
    type: str
    default_random: false
    name: uses_before_address
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after-address
    type: str
    default_random: false
    name: uses_after_address
  - help: dictionary JSON with a list of connections to configure
    choices: null
    default: null
    required: false
    option_strings:
    - --connection-list
    type: str
    default_random: false
    name: connection_list
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  help: Start an Executor. Executor is how Jina processes Document.
- name: flow
  options:
  - help: "\n    The name of this object.\n\n    This will be used in the following\
      \ places:\n    - how you refer to this object in Python/YAML/CLI\n    - visualization\n\
      \    - log message header\n    - ...\n\n    When not given, then the default\
      \ naming strategy will apply.\n                        "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: default
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The YAML path represents a flow. It can be either a local file path or a
      URL.
    choices: null
    default: null
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: "\n    The strategy on those inspect deployments in the flow.\n\n    If\
      \ `REMOVE` is given then all inspect deployments are removed when building the\
      \ flow.\n    "
    choices:
    - HANG
    - REMOVE
    - COLLECT
    default: COLLECT
    required: false
    option_strings:
    - --inspect
    type: str
    default_random: false
    name: inspect
  help: Start a Flow. Flow is how Jina streamlines and distributes Executors.
- name: ping
  options:
  - help: The target type to ping. For `executor` and `gateway`, checks the readiness
      of the individual service. For `flow` it checks the connectivity of the complete
      microservice architecture.
    choices:
    - flow
    - executor
    - gateway
    default: executor
    required: true
    option_strings: []
    type: str
    default_random: false
    name: target
  - help: The host address with port of a target Executor, Gateway or a Flow, e.g.
      0.0.0.0:8000. For Flow or Gateway, host can also indicate the protocol, grpc
      will be used if not provided, e.g http://0.0.0.0:8000
    choices: null
    default: null
    required: true
    option_strings: []
    type: str
    default_random: false
    name: host
  - help: '

      Timeout in millisecond of one check

      -1 for waiting forever

      '
    choices: null
    default: 3000
    required: false
    option_strings:
    - --timeout
    type: int
    default_random: false
    name: timeout
  - help: The number of readiness checks to perform
    choices: null
    default: 1
    required: false
    option_strings:
    - --attempts
    type: int
    default_random: false
    name: attempts
  - help: The minimum number of successful readiness checks, before exiting successfully
      with exit(0)
    choices: null
    default: 1
    required: false
    option_strings:
    - --min-successful-attempts
    type: int
    default_random: false
    name: min_successful_attempts
  help: Ping a remote Executor or a Flow.
- name: export
  options: []
  help: Export Jina API and Flow to JSONSchema, Kubernetes YAML, or SVG flowchart.
  methods:
  - name: flowchart
    options:
    - help: The input file path of a Flow YAML
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: flowpath
    - help: The output path
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: outpath
    - help: If set, then the flowchart is rendered vertically from top to down.
      choices: null
      default: false
      required: false
      option_strings:
      - --vertical-layout
      type: bool
      default_random: false
      name: vertical_layout
    help: null
  - name: kubernetes
    options:
    - help: The input file path of a Flow YAML
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: flowpath
    - help: The output path
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: outpath
    - help: The name of the k8s namespace to set for the configurations. If None,
        the name of the Flow will be used.
      choices: null
      default: null
      required: false
      option_strings:
      - --k8s-namespace
      type: str
      default_random: false
      name: k8s_namespace
    help: null
  - name: docker-compose
    options:
    - help: The input file path of a Flow YAML
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: flowpath
    - help: The output path
      choices: null
      default: null
      required: true
      option_strings: []
      type: str
      default_random: false
      name: outpath
    - help: The name of the network that will be used by the deployment name.
      choices: null
      default: null
      required: false
      option_strings:
      - --network_name
      type: str
      default_random: false
      name: network_name
    help: null
  - name: schema
    options:
    - help: The YAML file path for storing the exported API
      choices: null
      default: null
      required: false
      option_strings:
      - --yaml-path
      type: typing.List[str]
      default_random: false
      name: yaml_path
    - help: The JSON file path for storing the exported API
      choices: null
      default: null
      required: false
      option_strings:
      - --json-path
      type: typing.List[str]
      default_random: false
      name: json_path
    - help: The JSONSchema file path for storing the exported API
      choices: null
      default: null
      required: false
      option_strings:
      - --schema-path
      type: typing.List[str]
      default_random: false
      name: schema_path
    help: null
- name: new
  options:
  - help: The name of the project
    choices: null
    default: hello-jina
    required: true
    option_strings: []
    type: str
    default_random: false
    name: name
  help: Create a new Jina toy project with the predefined template.
- name: gateway
  options:
  - help: "\n    The name of this object.\n\n    This will be used in the following\
      \ places:\n    - how you refer to this object in Python/YAML/CLI\n    - visualization\n\
      \    - log message header\n    - ...\n\n    When not given, then the default\
      \ naming strategy will apply.\n                        "
    choices: null
    default: gateway
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: default
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: "\n    Number of requests fetched from the client before feeding into the\
      \ first Executor. \n    \n    Used to control the speed of data input into a\
      \ Flow. 0 disables prefetch (1000 requests is the default)"
    choices: null
    default: 1000
    required: false
    option_strings:
    - --prefetch
    type: int
    default_random: false
    name: prefetch
  - help: The title of this HTTP server. It will be used in automatics docs such as
      Swagger UI.
    choices: null
    default: null
    required: false
    option_strings:
    - --title
    type: str
    default_random: false
    name: title
  - help: The description of this HTTP server. It will be used in automatics docs
      such as Swagger UI.
    choices: null
    default: null
    required: false
    option_strings:
    - --description
    type: str
    default_random: false
    name: description
  - help: "\n        If set, a CORS middleware is added to FastAPI frontend to allow\
      \ cross-origin access.\n        "
    choices: null
    default: false
    required: false
    option_strings:
    - --cors
    type: bool
    default_random: false
    name: cors
  - help: 'If set, `/status` `/post` endpoints are removed from HTTP interface. '
    choices: null
    default: false
    required: false
    option_strings:
    - --no-debug-endpoints
    type: bool
    default_random: false
    name: no_debug_endpoints
  - help: "\n        If set, `/index`, `/search`, `/update`, `/delete` endpoints are\
      \ removed from HTTP interface.\n\n        Any executor that has `@requests(on=...)`\
      \ bound with those values will receive data requests.\n        "
    choices: null
    default: false
    required: false
    option_strings:
    - --no-crud-endpoints
    type: bool
    default_random: false
    name: no_crud_endpoints
  - help: "\n        A JSON string that represents a map from executor endpoints (`@requests(on=...)`)\
      \ to HTTP endpoints.\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --expose-endpoints
    type: str
    default_random: false
    name: expose_endpoints
  - help: '

      Dictionary of kwargs arguments that will be passed to Uvicorn server when starting
      the server


      More details can be found in Uvicorn docs: https://www.uvicorn.org/settings/


      '
    choices: null
    default: null
    required: false
    option_strings:
    - --uvicorn-kwargs
    type: dict
    default_random: false
    name: uvicorn_kwargs
  - help: "\n        the path to the certificate file\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --ssl-certfile
    type: str
    default_random: false
    name: ssl_certfile
  - help: "\n        the path to the key file\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --ssl-keyfile
    type: str
    default_random: false
    name: ssl_keyfile
  - help: 'If set, /graphql endpoint is added to HTTP interface. '
    choices: null
    default: false
    required: false
    option_strings:
    - --expose-graphql-endpoint
    type: bool
    default_random: false
    name: expose_graphql_endpoint
  - help: 'Communication protocol of the server exposed by the Gateway. This can be
      a single value or a list of protocols, depending on your chosen Gateway. Choose
      the convenient protocols from: [''GRPC'', ''HTTP'', ''WEBSOCKET''].'
    choices:
    - GRPC
    - HTTP
    - WEBSOCKET
    default:
    - "GRPC"
    required: false
    option_strings:
    - --protocol
    - --protocols
    type: typing.List[str]
    default_random: false
    name: protocol
  - help: The host address of the runtime, by default it is 0.0.0.0. In the case of
      an external Executor (`--external` or `external=True`) this can be a list of
      hosts, separated by commas. Then, every resulting address will be considered
      as one replica of the Executor.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    - --host-in
    type: str
    default_random: false
    name: host
  - help: If set, respect the http_proxy and https_proxy environment variables. otherwise,
      it will unset these proxy variables before start. gRPC seems to prefer no proxy
    choices: null
    default: false
    required: false
    option_strings:
    - --proxy
    type: bool
    default_random: false
    name: proxy
  - help: "\n        The config of the gateway, it could be one of the followings:\n\
      \        * the string literal of an Gateway class name\n        * a Gateway\
      \ YAML file (.yml, .yaml, .jaml)\n        * a docker image (must start with\
      \ `docker://`)\n        * the string literal of a YAML config (must start with\
      \ `!` or `jtype: `)\n        * the string literal of a JSON config\n\n     \
      \   When use it under Python, one can use the following values additionally:\n\
      \        - a Python dict that represents the config\n        - a text file stream\
      \ has `.read()` interface\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: '

      The customized python modules need to be imported before loading the gateway


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      gateway can be defined in a single file, or an ``__init__.py`` file if you have
      multiple files,

      which should be structured as a python package.

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: 'Dictionary of kwargs arguments that will be passed to the grpc server as
      options when starting the server, example : {''grpc.max_send_message_length'':
      -1}'
    choices: null
    default: null
    required: false
    option_strings:
    - --grpc-server-options
    type: dict
    default_random: false
    name: grpc_server_options
  - help: Routing graph for the gateway
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --graph-description
    type: str
    default_random: false
    name: graph_description
  - help: Dictionary stating which filtering conditions each Executor in the graph
      requires to receive Documents.
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --graph-conditions
    type: str
    default_random: false
    name: graph_conditions
  - help: JSON dictionary with the input addresses of each Deployment
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --deployments-addresses
    type: str
    default_random: false
    name: deployments_addresses
  - help: JSON dictionary with the request metadata for each Deployment
    choices: null
    default: '{}'
    required: false
    option_strings:
    - --deployments-metadata
    type: str
    default_random: false
    name: deployments_metadata
  - help: list JSON disabling the built-in merging mechanism for each Deployment listed
    choices: null
    default: '[]'
    required: false
    option_strings:
    - --deployments-no-reduce
    - --deployments-disable-reduce
    type: str
    default_random: false
    name: deployments_no_reduce
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. For more details, check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices:
    - NoCompression
    - Deflate
    - Gzip
    default: null
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  - help: The runtime class to run inside the Pod
    choices: null
    default: GatewayRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: If set, the current Pod/Deployment can not be further chained, and the next
      `.add()` will chain after the last Pod/Deployment not this current one.
    choices: null
    default: false
    required: false
    option_strings:
    - --floating
    type: bool
    default_random: false
    name: floating
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: The port on which the prometheus server is exposed, default is a random
      port between [49152, 65535]
    choices: null
    default: '63637'
    required: false
    option_strings:
    - --port-monitoring
    type: str
    default_random: true
    default_factory: random_identity
    name: port_monitoring
  - help: Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)
    choices: null
    default: -1
    required: false
    option_strings:
    - --retries
    type: int
    default_random: false
    name: retries
  - help: If set, the sdk implementation of the OpenTelemetry tracer will be available
      and will be enabled for automatic tracing of requests and customer span creation.
      Otherwise a no-op implementation will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --tracing
    type: bool
    default_random: false
    name: tracing
  - help: If tracing is enabled, this hostname will be used to configure the trace
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-host
    type: str
    default_random: false
    name: traces_exporter_host
  - help: If tracing is enabled, this port will be used to configure the trace exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-port
    type: int
    default_random: false
    name: traces_exporter_port
  - help: If set, the sdk implementation of the OpenTelemetry metrics will be available
      for default monitoring and custom measurements. Otherwise a no-op implementation
      will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --metrics
    type: bool
    default_random: false
    name: metrics
  - help: If tracing is enabled, this hostname will be used to configure the metrics
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-host
    type: str
    default_random: false
    name: metrics_exporter_host
  - help: If tracing is enabled, this port will be used to configure the metrics exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-port
    type: int
    default_random: false
    name: metrics_exporter_port
  help: Start a Gateway that receives client Requests via gRPC/REST interface
- name: auth
  options: []
  help: Login to Jina AI with your GitHub/Google/Email account
  methods:
  - name: login
    options:
    - help: Force to login
      choices: null
      default: false
      required: false
      option_strings:
      - -f
      - --force
      type: bool
      default_random: false
      name: force
    help: Login to Jina AI Ecosystem
  - name: logout
    options: []
    help: Logout from Jina AI Ecosystem
    methods: []
  - name: token
    options: []
    help: Commands for Personal Access Token
    methods:
    - name: create
      options:
      - help: Validity period (days)
        choices: null
        default: 7
        required: false
        option_strings:
        - -e
        - --expire
        type: int
        default_random: false
        name: expire
      - help: Name of Personal Access Token
        choices: null
        default: null
        required: true
        option_strings: []
        type: str
        default_random: false
        name: name
      help: Create a Personal Access Token
    - name: delete
      options:
      - help: Name of Personal Access Token which you want to delete
        choices: null
        default: null
        required: true
        option_strings: []
        type: str
        default_random: false
        name: name
      help: Revoke a Personal Access Token
    - name: list
      options: []
      help: List all Personal Access Tokens
      methods: []
- name: hub
  options: []
  help: Push/Pull an Executor to/from Jina Hub
  methods:
  - name: new
    options:
    - help: the name of the Executor
      choices: null
      default: null
      required: false
      option_strings:
      - --name
      type: str
      default_random: false
      name: name
    - help: the path to store the Executor
      choices: null
      default: null
      required: false
      option_strings:
      - --path
      type: str
      default_random: false
      name: path
    - help: If set, always set up advance configuration like description, keywords
        and url
      choices: null
      default: false
      required: false
      option_strings:
      - --advance-configuration
      type: bool
      default_random: false
      name: advance_configuration
    - help: the short description of the Executor
      choices: null
      default: null
      required: false
      option_strings:
      - --description
      type: str
      default_random: false
      name: description
    - help: some keywords to help people search your Executor (separated by comma)
      choices: null
      default: null
      required: false
      option_strings:
      - --keywords
      type: str
      default_random: false
      name: keywords
    - help: the URL of your GitHub repo
      choices: null
      default: null
      required: false
      option_strings:
      - --url
      type: str
      default_random: false
      name: url
    - help: The Dockerfile template to use for the Executor
      choices:
      - cpu
      - tf-gpu
      - torch-gpu
      - jax-gpu
      default: null
      required: false
      option_strings:
      - --dockerfile
      type: str
      default_random: false
      name: dockerfile
    help: Create a new executor using the template
  - name: push
    options:
    - help: If set, Hub executor usage will not be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --no-usage
      type: bool
      default_random: false
      name: no_usage
    - help: If set, more information will be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --verbose
      type: bool
      default_random: false
      name: verbose
    - help: The Executor folder to be pushed to Jina Hub
      choices: null
      default: null
      required: true
      option_strings: []
      type: dir_path
      default_random: false
      name: path
    - help: The file path to the Dockerfile (default is `${cwd}/Dockerfile`)
      choices: null
      default: null
      required: false
      option_strings:
      - -f
      - --dockerfile
      type: None
      default_random: false
      name: dockerfile
    - help: If set, push will overwrite the Executor on the Hub that shares the same
        NAME or UUID8 identifier
      choices: null
      default: null
      required: false
      option_strings:
      - --force-update
      - --force
      type: str
      default_random: false
      name: force_update
    - help: The secret for overwrite a Hub executor
      choices: null
      default: null
      required: false
      option_strings:
      - --secret
      type: str
      default_random: false
      name: secret
    - help: If set, "--no-cache" option will be added to the Docker build.
      choices: null
      default: false
      required: false
      option_strings:
      - --no-cache
      type: bool
      default_random: false
      name: no_cache
    - help: If set, the pushed executor is visible to public
      choices: null
      default: ==SUPPRESS==
      required: false
      option_strings:
      - --public
      type: bool
      default_random: false
      name: public
    - help: If set, the pushed executor is invisible to public
      choices: null
      default: ==SUPPRESS==
      required: false
      option_strings:
      - --private
      type: bool
      default_random: false
      name: private
    help: Push an executor package to Jina hub
  - name: pull
    options:
    - help: If set, Hub executor usage will not be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --no-usage
      type: bool
      default_random: false
      name: no_usage
    - help: The URI of the executor to pull (e.g., jinaai[+docker]://<username>/NAME)
      choices: null
      default: null
      required: true
      option_strings: []
      type: hub_uri
      default_random: false
      name: uri
    - help: If set, install `requirements.txt` in the Hub Executor bundle to local
      choices: null
      default: false
      required: false
      option_strings:
      - --install-requirements
      type: bool
      default_random: false
      name: install_requirements
    - help: If set, always pull the latest Hub Executor bundle even it exists on local
      choices: null
      default: false
      required: false
      option_strings:
      - --force-update
      - --force
      type: bool
      default_random: false
      name: force_update
    help: Download an executor image/package from Jina hub
  - name: status
    options:
    - help: The Executor folder to be pushed to Jina Hub.
      choices: null
      default: .
      required: false
      option_strings: []
      type: dir_path
      default_random: false
      name: path
    - help: If set, you can get the specified building state of a pushed Executor.
      choices: null
      default: null
      required: false
      option_strings:
      - --id
      type: str
      default_random: false
      name: id
    - help: If set, more building status information of a pushed Executor will be
        printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --verbose
      type: bool
      default_random: false
      name: verbose
    - help: If set, history building status information of a pushed Executor will
        be printed.
      choices: null
      default: false
      required: false
      option_strings:
      - --replay
      type: bool
      default_random: false
      name: replay
    help: Query an executor building status of of a pushed Executor from Jina hub
  - name: list
    options: []
    help: List your local Jina Executors
    methods: []
- name: cloud
  options:
  - help: Set the loglevel of the logger
    choices:
    - DEBUG
    - INFO
    - CRITICAL
    - NOTSET
    default: INFO
    required: false
    option_strings:
    - --loglevel
    type: str
    default_random: false
    name: loglevel
  help: Manage Flows on Jina Cloud
- name: help
  options:
  - help: Lookup the usage & mention of the argument name in Jina API. The name can
      be fuzzy
    choices: null
    default: null
    required: true
    option_strings: []
    type: str
    default_random: false
    name: query
  help: Show help text of a CLI argument
- name: pod
  options:
  - help: "\n    The name of this object.\n\n    This will be used in the following\
      \ places:\n    - how you refer to this object in Python/YAML/CLI\n    - visualization\n\
      \    - log message header\n    - ...\n\n    When not given, then the default\
      \ naming strategy will apply.\n                        "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: default
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * the string literal of an Executor class name\n        * an Executor\
      \ YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub Executor (must start\
      \ with `jinahub://` or `jinahub+docker://`)\n        * a docker image (must\
      \ start with `docker://`)\n        * the string literal of a YAML config (must\
      \ start with `!` or `jtype: `)\n        * the string literal of a JSON config\n\
      \n        When use it under Python, one can use the following values additionally:\n\
      \        - a Python dict that represents the config\n        - a text file stream\
      \ has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: List of exceptions that will cause the Executor to shut down.
    choices: null
    default: []
    required: false
    option_strings:
    - --exit-on-exceptions
    type: typing.List[str]
    default_random: false
    name: exit_on_exceptions
  - help: Disable the built-in reduction mechanism. Set this if the reduction is to
      be handled by the Executor itself by operating on a `docs_matrix` or `docs_map`
    choices: null
    default: false
    required: false
    option_strings:
    - --no-reduce
    - --disable-reduce
    type: bool
    default_random: false
    name: no_reduce
  - help: 'Dictionary of kwargs arguments that will be passed to the grpc server as
      options when starting the server, example : {''grpc.max_send_message_length'':
      -1}'
    choices: null
    default: null
    required: false
    option_strings:
    - --grpc-server-options
    type: dict
    default_random: false
    name: grpc_server_options
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: "\nThe path on the host to be mounted inside the container. \n\nNote, \n\
      - If separated by `:`, then the first part will be considered as the local host\
      \ path and the second part is the path in the container system. \n- If no split\
      \ provided, then the basename of that directory will be mounted into container's\
      \ root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into\
      \ `/my-workspace` inside the container. \n- All volumes are mounted with read-write\
      \ mode.\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --volumes
    type: typing.List[str]
    default_random: false
    name: volumes
  - help: "\n    This argument allows dockerized Jina Executors to discover local\
      \ gpu devices.\n    \n    Note, \n    - To access all gpus, use `--gpus all`.\n\
      \    - To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.\n \
      \   - To access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`\n\
      \    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`\n\
      \    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n\
      \        "
    choices: null
    default: null
    required: false
    option_strings:
    - --gpus
    type: str
    default_random: false
    name: gpus
  - help: Do not automatically mount a volume for dockerized Executors.
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-auto-volume
    type: bool
    default_random: false
    name: disable_auto_volume
  - help: The host address of the runtime, by default it is 0.0.0.0. In the case of
      an external Executor (`--external` or `external=True`) this can be a list of
      hosts, separated by commas. Then, every resulting address will be considered
      as one replica of the Executor.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    - --host-in
    type: str
    default_random: false
    name: host
  - help: The runtime class to run inside the Pod
    choices: null
    default: WorkerRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: If set, the current Pod/Deployment can not be further chained, and the next
      `.add()` will chain after the last Pod/Deployment not this current one.
    choices: null
    default: false
    required: false
    option_strings:
    - --floating
    type: bool
    default_random: false
    name: floating
  - help: If set, the Executor reloads the modules as they change
    choices: null
    default: false
    required: false
    option_strings:
    - --reload
    type: bool
    default_random: false
    name: reload
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: The port on which the prometheus server is exposed, default is a random
      port between [49152, 65535]
    choices: null
    default: '52530'
    required: false
    option_strings:
    - --port-monitoring
    type: str
    default_random: true
    default_factory: random_identity
    name: port_monitoring
  - help: Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)
    choices: null
    default: -1
    required: false
    option_strings:
    - --retries
    type: int
    default_random: false
    name: retries
  - help: If set, the sdk implementation of the OpenTelemetry tracer will be available
      and will be enabled for automatic tracing of requests and customer span creation.
      Otherwise a no-op implementation will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --tracing
    type: bool
    default_random: false
    name: tracing
  - help: If tracing is enabled, this hostname will be used to configure the trace
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-host
    type: str
    default_random: false
    name: traces_exporter_host
  - help: If tracing is enabled, this port will be used to configure the trace exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-port
    type: int
    default_random: false
    name: traces_exporter_port
  - help: If set, the sdk implementation of the OpenTelemetry metrics will be available
      for default monitoring and custom measurements. Otherwise a no-op implementation
      will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --metrics
    type: bool
    default_random: false
    name: metrics
  - help: If tracing is enabled, this hostname will be used to configure the metrics
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-host
    type: str
    default_random: false
    name: metrics_exporter_host
  - help: If tracing is enabled, this port will be used to configure the metrics exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-port
    type: int
    default_random: false
    name: metrics_exporter_port
  - help: If set, install `requirements.txt` in the Hub Executor bundle to local
    choices: null
    default: false
    required: false
    option_strings:
    - --install-requirements
    type: bool
    default_random: false
    name: install_requirements
  - help: If set, always pull the latest Hub Executor bundle even it exists on local
    choices: null
    default: false
    required: false
    option_strings:
    - --force-update
    - --force
    type: bool
    default_random: false
    name: force_update
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. For more details, check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices:
    - NoCompression
    - Deflate
    - Gzip
    default: null
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before-address
    type: str
    default_random: false
    name: uses_before_address
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after-address
    type: str
    default_random: false
    name: uses_after_address
  - help: dictionary JSON with a list of connections to configure
    choices: null
    default: null
    required: false
    option_strings:
    - --connection-list
    type: str
    default_random: false
    name: connection_list
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  help: Start a Pod. You should rarely use this directly unless you are doing low-level
    orchestration
- name: deployment
  options:
  - help: "\n    The name of this object.\n\n    This will be used in the following\
      \ places:\n    - how you refer to this object in Python/YAML/CLI\n    - visualization\n\
      \    - log message header\n    - ...\n\n    When not given, then the default\
      \ naming strategy will apply.\n                        "
    choices: null
    default: null
    required: false
    option_strings:
    - --name
    type: str
    default_random: false
    name: name
  - help: The working directory for any IO operations in this object. If not set,
      then derive from its parent `workspace`.
    choices: null
    default: null
    required: false
    option_strings:
    - --workspace
    type: str
    default_random: false
    name: workspace
  - help: The YAML config of the logger used in this object.
    choices: null
    default: default
    required: false
    option_strings:
    - --log-config
    type: str
    default_random: false
    name: log_config
  - help: If set, then no log will be emitted from this object.
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet
    type: bool
    default_random: false
    name: quiet
  - help: If set, then exception stack information will not be added to the log
    choices: null
    default: false
    required: false
    option_strings:
    - --quiet-error
    type: bool
    default_random: false
    name: quiet_error
  - help: The timeout in milliseconds of the control request, -1 for waiting forever
    choices: null
    default: 60
    required: false
    option_strings:
    - --timeout-ctrl
    type: int
    default_random: false
    name: timeout_ctrl
  - help: "\n    The polling strategy of the Deployment and its endpoints (when `shards>1`).\n\
      \    Can be defined for all endpoints of a Deployment or by endpoint.\n    Define\
      \ per Deployment:\n    - ANY: only one (whoever is idle) Pod polls the message\n\
      \    - ALL: all Pods poll the message (like a broadcast)\n    Define per Endpoint:\n\
      \    JSON dict, {endpoint: PollingType}\n    {'/custom': 'ALL', '/search': 'ANY',\
      \ '*': 'ANY'}\n    \n    "
    choices: null
    default: ANY
    required: false
    option_strings:
    - --polling
    type: str
    default_random: false
    name: polling
  - help: The number of shards in the deployment running at the same time. For more
      details check https://docs.jina.ai/fundamentals/flow/create-flow/#complex-flow-topologies
    choices: null
    default: 1
    required: false
    option_strings:
    - --shards
    type: int
    default_random: false
    name: shards
  - help: The number of replicas in the deployment
    choices: null
    default: 1
    required: false
    option_strings:
    - --replicas
    type: int
    default_random: false
    name: replicas
  - help: If set, only native Executors is allowed, and the Executor is always run
      inside WorkerRuntime.
    choices: null
    default: false
    required: false
    option_strings:
    - --native
    type: bool
    default_random: false
    name: native
  - help: "\n        The config of the executor, it could be one of the followings:\n\
      \        * the string literal of an Executor class name\n        * an Executor\
      \ YAML file (.yml, .yaml, .jaml)\n        * a Jina Hub Executor (must start\
      \ with `jinahub://` or `jinahub+docker://`)\n        * a docker image (must\
      \ start with `docker://`)\n        * the string literal of a YAML config (must\
      \ start with `!` or `jtype: `)\n        * the string literal of a JSON config\n\
      \n        When use it under Python, one can use the following values additionally:\n\
      \        - a Python dict that represents the config\n        - a text file stream\
      \ has `.read()` interface\n        "
    choices: null
    default: BaseExecutor
    required: false
    option_strings:
    - --uses
    type: str
    default_random: false
    name: uses
  - help: "\n    Dictionary of keyword arguments that will override the `with` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-with
    type: dict
    default_random: false
    name: uses_with
  - help: "\n    Dictionary of keyword arguments that will override the `metas` configuration\
      \ in `uses`\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-metas
    type: dict
    default_random: false
    name: uses_metas
  - help: "\n        Dictionary of keyword arguments that will override the `requests`\
      \ configuration in `uses`\n        "
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-requests
    type: dict
    default_random: false
    name: uses_requests
  - help: '

      The customized python modules need to be imported before loading the executor


      Note that the recommended way is to only import a single module - a simple python
      file, if your

      executor can be defined in a single file, or an ``__init__.py`` file if you
      have multiple files,

      which should be structured as a python package. For more details, please see
      the

      `Executor cookbook <https://docs.jina.ai/fundamentals/executor/executor-files/>`__

      '
    choices: null
    default: null
    required: false
    option_strings:
    - --py-modules
    type: typing.List[str]
    default_random: false
    name: py_modules
  - help: "\nThe type of array `tensor` and `embedding` will be serialized to.\n\n\
      Supports the same types as `docarray.to_protobuf(.., ndarray_type=...)`, which\
      \ can be found \n`here <https://docarray.jina.ai/fundamentals/document/serialization/#from-to-protobuf>`.\n\
      Defaults to retaining whatever type is returned by the Executor.\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --output-array-type
    type: str
    default_random: false
    name: output_array_type
  - help: List of exceptions that will cause the Executor to shut down.
    choices: null
    default: []
    required: false
    option_strings:
    - --exit-on-exceptions
    type: typing.List[str]
    default_random: false
    name: exit_on_exceptions
  - help: Disable the built-in reduction mechanism. Set this if the reduction is to
      be handled by the Executor itself by operating on a `docs_matrix` or `docs_map`
    choices: null
    default: false
    required: false
    option_strings:
    - --no-reduce
    - --disable-reduce
    type: bool
    default_random: false
    name: no_reduce
  - help: 'Dictionary of kwargs arguments that will be passed to the grpc server as
      options when starting the server, example : {''grpc.max_send_message_length'':
      -1}'
    choices: null
    default: null
    required: false
    option_strings:
    - --grpc-server-options
    type: dict
    default_random: false
    name: grpc_server_options
  - help: The entrypoint command overrides the ENTRYPOINT in Docker image. when not
      set then the Docker image ENTRYPOINT takes effective.
    choices: null
    default: null
    required: false
    option_strings:
    - --entrypoint
    type: str
    default_random: false
    name: entrypoint
  - help: "\nDictionary of kwargs arguments that will be passed to Docker SDK when\
      \ starting the docker '\ncontainer. \n\nMore details can be found in the Docker\
      \ SDK docs:  https://docker-py.readthedocs.io/en/stable/\n\n"
    choices: null
    default: null
    required: false
    option_strings:
    - --docker-kwargs
    type: dict
    default_random: false
    name: docker_kwargs
  - help: "\nThe path on the host to be mounted inside the container. \n\nNote, \n\
      - If separated by `:`, then the first part will be considered as the local host\
      \ path and the second part is the path in the container system. \n- If no split\
      \ provided, then the basename of that directory will be mounted into container's\
      \ root path, e.g. `--volumes=\"/user/test/my-workspace\"` will be mounted into\
      \ `/my-workspace` inside the container. \n- All volumes are mounted with read-write\
      \ mode.\n    "
    choices: null
    default: null
    required: false
    option_strings:
    - --volumes
    type: typing.List[str]
    default_random: false
    name: volumes
  - help: "\n    This argument allows dockerized Jina Executors to discover local\
      \ gpu devices.\n    \n    Note, \n    - To access all gpus, use `--gpus all`.\n\
      \    - To access multiple gpus, e.g. make use of 2 gpus, use `--gpus 2`.\n \
      \   - To access specified gpus based on device id, use `--gpus device=[YOUR-GPU-DEVICE-ID]`\n\
      \    - To access specified gpus based on multiple device id, use `--gpus device=[YOUR-GPU-DEVICE-ID1],device=[YOUR-GPU-DEVICE-ID2]`\n\
      \    - To specify more parameters, use `--gpus device=[YOUR-GPU-DEVICE-ID],runtime=nvidia,capabilities=display\n\
      \        "
    choices: null
    default: null
    required: false
    option_strings:
    - --gpus
    type: str
    default_random: false
    name: gpus
  - help: Do not automatically mount a volume for dockerized Executors.
    choices: null
    default: false
    required: false
    option_strings:
    - --disable-auto-volume
    type: bool
    default_random: false
    name: disable_auto_volume
  - help: The host address of the runtime, by default it is 0.0.0.0. In the case of
      an external Executor (`--external` or `external=True`) this can be a list of
      hosts, separated by commas. Then, every resulting address will be considered
      as one replica of the Executor.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    - --host-in
    type: str
    default_random: false
    name: host
  - help: The runtime class to run inside the Pod
    choices: null
    default: WorkerRuntime
    required: false
    option_strings:
    - --runtime-cls
    type: str
    default_random: false
    name: runtime_cls
  - help: The timeout in milliseconds of a Pod waits for the runtime to be ready,
      -1 for waiting forever
    choices: null
    default: 600000
    required: false
    option_strings:
    - --timeout-ready
    type: int
    default_random: false
    name: timeout_ready
  - help: The map of environment variables that are available inside runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --env
    type: dict
    default_random: false
    name: env
  - help: If set, the current Pod/Deployment can not be further chained, and the next
      `.add()` will chain after the last Pod/Deployment not this current one.
    choices: null
    default: false
    required: false
    option_strings:
    - --floating
    type: bool
    default_random: false
    name: floating
  - help: If set, the Executor reloads the modules as they change
    choices: null
    default: false
    required: false
    option_strings:
    - --reload
    type: bool
    default_random: false
    name: reload
  - help: If set, spawn an http server with a prometheus endpoint to expose metrics
    choices: null
    default: false
    required: false
    option_strings:
    - --monitoring
    type: bool
    default_random: false
    name: monitoring
  - help: The port on which the prometheus server is exposed, default is a random
      port between [49152, 65535]
    choices: null
    default: '65085'
    required: false
    option_strings:
    - --port-monitoring
    type: str
    default_random: true
    default_factory: random_identity
    name: port_monitoring
  - help: Number of retries per gRPC call. If <0 it defaults to max(3, num_replicas)
    choices: null
    default: -1
    required: false
    option_strings:
    - --retries
    type: int
    default_random: false
    name: retries
  - help: If set, the sdk implementation of the OpenTelemetry tracer will be available
      and will be enabled for automatic tracing of requests and customer span creation.
      Otherwise a no-op implementation will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --tracing
    type: bool
    default_random: false
    name: tracing
  - help: If tracing is enabled, this hostname will be used to configure the trace
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-host
    type: str
    default_random: false
    name: traces_exporter_host
  - help: If tracing is enabled, this port will be used to configure the trace exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-port
    type: int
    default_random: false
    name: traces_exporter_port
  - help: If set, the sdk implementation of the OpenTelemetry metrics will be available
      for default monitoring and custom measurements. Otherwise a no-op implementation
      will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --metrics
    type: bool
    default_random: false
    name: metrics
  - help: If tracing is enabled, this hostname will be used to configure the metrics
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-host
    type: str
    default_random: false
    name: metrics_exporter_host
  - help: If tracing is enabled, this port will be used to configure the metrics exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-port
    type: int
    default_random: false
    name: metrics_exporter_port
  - help: If set, install `requirements.txt` in the Hub Executor bundle to local
    choices: null
    default: false
    required: false
    option_strings:
    - --install-requirements
    type: bool
    default_random: false
    name: install_requirements
  - help: If set, always pull the latest Hub Executor bundle even it exists on local
    choices: null
    default: false
    required: false
    option_strings:
    - --force-update
    - --force
    type: bool
    default_random: false
    name: force_update
  - help: The compression mechanism used when sending requests from the Head to the
      WorkerRuntimes. For more details, check https://grpc.github.io/grpc/python/grpc.html#compression.
    choices:
    - NoCompression
    - Deflate
    - Gzip
    default: null
    required: false
    option_strings:
    - --compression
    type: str
    default_random: false
    name: compression
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before-address
    type: str
    default_random: false
    name: uses_before_address
  - help: The address of the uses-before runtime
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after-address
    type: str
    default_random: false
    name: uses_after_address
  - help: dictionary JSON with a list of connections to configure
    choices: null
    default: null
    required: false
    option_strings:
    - --connection-list
    type: str
    default_random: false
    name: connection_list
  - help: The timeout in milliseconds used when sending data requests to Executors,
      -1 means no timeout, disabled by default
    choices: null
    default: null
    required: false
    option_strings:
    - --timeout-send
    type: int
    default_random: false
    name: timeout_send
  - help: The executor attached before the Pods described by --uses, typically before
      sending to all shards, accepted type follows `--uses`. This argument only applies
      for sharded Deployments (shards > 1).
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-before
    type: str
    default_random: false
    name: uses_before
  - help: The executor attached after the Pods described by --uses, typically used
      for receiving from all shards, accepted type follows `--uses`. This argument
      only applies for sharded Deployments (shards > 1).
    choices: null
    default: null
    required: false
    option_strings:
    - --uses-after
    type: str
    default_random: false
    name: uses_after
  - help: The condition that the documents need to fulfill before reaching the Executor.The
      condition can be defined in the form of a `DocArray query condition <https://docarray.jina.ai/fundamentals/documentarray/find/#query-by-conditions>`
    choices: null
    default: null
    required: false
    option_strings:
    - --when
    type: dict
    default_random: false
    name: when
  - help: The Deployment will be considered an external Deployment that has been started
      independently from the Flow.This Deployment will not be context managed by the
      Flow.
    choices: null
    default: false
    required: false
    option_strings:
    - --external
    type: bool
    default_random: false
    name: external
  - help: The metadata to be passed to the gRPC request.
    choices: null
    default: null
    required: false
    option_strings:
    - --grpc-metadata
    type: dict
    default_random: false
    name: grpc_metadata
  - help: If set, connect to deployment using tls encryption
    choices: null
    default: false
    required: false
    option_strings:
    - --tls
    type: bool
    default_random: false
    name: tls
  help: Start a Deployment. You should rarely use this directly unless you are doing
    low-level orchestration
- name: client
  options:
  - help: The host address of the runtime, by default it is 0.0.0.0. In the case of
      an external Executor (`--external` or `external=True`) this can be a list of
      hosts, separated by commas. Then, every resulting address will be considered
      as one replica of the Executor.
    choices: null
    default: 0.0.0.0
    required: false
    option_strings:
    - --host
    - --host-in
    type: str
    default_random: false
    name: host
  - help: If set, respect the http_proxy and https_proxy environment variables. otherwise,
      it will unset these proxy variables before start. gRPC seems to prefer no proxy
    choices: null
    default: false
    required: false
    option_strings:
    - --proxy
    type: bool
    default_random: false
    name: proxy
  - help: The port of the Gateway, which the client should connect to.
    choices: null
    default: null
    required: false
    option_strings:
    - --port
    type: int
    default_random: false
    name: port
  - help: If set, connect to gateway using tls encryption
    choices: null
    default: false
    required: false
    option_strings:
    - --tls
    type: bool
    default_random: false
    name: tls
  - help: 'If set, then the input and output of this Client work in an asynchronous
      manner. '
    choices: null
    default: false
    required: false
    option_strings:
    - --asyncio
    type: bool
    default_random: false
    name: asyncio
  - help: If set, the sdk implementation of the OpenTelemetry tracer will be available
      and will be enabled for automatic tracing of requests and customer span creation.
      Otherwise a no-op implementation will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --tracing
    type: bool
    default_random: false
    name: tracing
  - help: If tracing is enabled, this hostname will be used to configure the trace
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-host
    type: str
    default_random: false
    name: traces_exporter_host
  - help: If tracing is enabled, this port will be used to configure the trace exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --traces-exporter-port
    type: int
    default_random: false
    name: traces_exporter_port
  - help: If set, the sdk implementation of the OpenTelemetry metrics will be available
      for default monitoring and custom measurements. Otherwise a no-op implementation
      will be provided.
    choices: null
    default: false
    required: false
    option_strings:
    - --metrics
    type: bool
    default_random: false
    name: metrics
  - help: If tracing is enabled, this hostname will be used to configure the metrics
      exporter agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-host
    type: str
    default_random: false
    name: metrics_exporter_host
  - help: If tracing is enabled, this port will be used to configure the metrics exporter
      agent.
    choices: null
    default: null
    required: false
    option_strings:
    - --metrics-exporter-port
    type: int
    default_random: false
    name: metrics_exporter_port
  - help: Communication protocol between server and client.
    choices:
    - GRPC
    - HTTP
    - WEBSOCKET
    default: GRPC
    required: false
    option_strings:
    - --protocol
    type: str
    default_random: false
    name: protocol
  help: Start a Python client that connects to a Jina Gateway
revision: null
